<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script> -->
  <!-- <script type="text/javascript" src="js/hidebib.js"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>

  <title>Hu Yu</title>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  
  <meta name="author" content="Hu Yu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" type="text/css" href="css/style.css">
  <link rel="icon" type="image/png" href="images/Hu-icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Hu Yu</name>
              </p>
              <p>I am a forth-year PhD student at <a href="https://www.ustc.edu.cn/">University of Science and Technology of China</a>, advised by <a href="https://bivlab123.github.io/">Feng Zhao</a>. 
              </p>
              <p>My research interest lies in diffusion model, autoregressive model, unified understanding and generation model, and world model. Any discussions and cooperations are warmly welcomed!
              </p>
              <p style="text-align:center">
                <a href="mailto:yuhu520@mail.ustc.edu.cn">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Efvaho0AAAAJ&hl=zh-CN">Google Scholar</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/HuYu.png"><img style="width:100%;max-width:100%;border-radius:50%" alt="profile photo" src="images/HuYu.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <ul>
              <li>1 paper accepted to <b>CVPR 2025</b> as <b>Highlight</b></li>  
              <li>2 paper accepted to <b>ECCV 2024</b></li> 
              <li>1 paper accepted to <b>ACM MM 2024</b></li> 
              <li>1 paper accepted to <b>WACV 2024</b></li>  
              <li>1 paper accepted to <b>NeurIPS 2023</b> as <b>Spotlight</b></li>  
              <li>2 paper accepted to <b>CVPR 2023</b></li> 
              <li>1 paper accepted to <b>NeurIPS 2022</b> as <b>Featured paper</b></li>  
              <li>2 paper accepted to <b>ACM MM 2022</b></li> 
              <li>2 paper accepted to <b>ECCV 2022</b></li> 
            </ul>
          </td>
        </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                In the last year, my research mainly lies in autoregressive image & video generation, and unified understanding & generation model. For full list of my publications, please refer to my <a href="https://scholar.google.com/citations?user=Efvaho0AAAAJ&hl=zh-CN">Google Scholar</a> for full publications.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/Paper/FAR.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://www.arxiv.org/abs/2506.14168">
                  <papertitle>VideoMAR: Autoregressive Video Generation with Continuous Tokens</papertitle>
                </a>
                <br>
                <strong>Hu Yu</strong>,
                Biao Gong, 
                Hangjie Yuan, 
                DanDan Zheng, 
                Weilong Chai,
                Jingdong Chen, 
                Kecheng Zheng, 
                Feng Zhao
                <br>
                <em>Arxiv</em>
                <br>
              </p>
              <div class="paper" id="yu2022cmtdeeplab">
                <a href="https://www.arxiv.org/abs/2506.14168">paper</a> &nbsp/&nbsp
                <a href="https://yuhuustc.github.io//projects/VideoMAR.html">project page</a>
              </div>
            </td>
          </tr>
          
          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/Paper/FAR.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://arxiv.org/abs/2503.05305">
                  <papertitle>Frequency Autoregressive Image Generation with Continuous Tokens</papertitle>
                </a>
                <br>
                <strong>Hu Yu</strong>,
                Hao Luo, 
                HangJie Yuan, 
                Yu Rong, 
                Feng Zhao
                <br>
                <em>Arxiv</em>
                <br>
              </p>
              <div class="paper" id="yu2022cmtdeeplab">
                <a href="https://arxiv.org/abs/2503.05305">paper</a> &nbsp/&nbsp
                <a href="https://yuhuustc.github.io//projects/FAR.html">project page</a>
              </div>
            </td>
          </tr>

          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/Paper/DualFast.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://arxiv.org/pdf/2506.13058">
                  <papertitle>DualFast: Dual-Speedup Framework for Fast Sampling of Diffusion Models</papertitle>
                </a>
                <br>
                <strong>Hu Yu</strong>,
                Hao Luo, 
                Fan Wang, 
                Feng Zhao
                <br>
                <em>Arxiv</em>
                <br>
              </p>
              <div class="paper" id="kim2022tubeformer">
                <a href="https://arxiv.org/pdf/2506.13058">paper</a> &nbsp/&nbsp
              </div>
            </td>
          </tr>
          
          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/Paper/Uncovering.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://arxiv.org/abs/2404.01154">
                  <papertitle>Uncovering the Text Embedding in Text-to-Image Diffusion Models</papertitle>
                </a>
                <br>
                <strong>Hu Yu</strong>,
                Hao Luo, 
                Fan Wang, 
                Feng Zhao
                <br>
                <em>Arxiv</em>
                <br>
              </p>
              <div class="paper" id="kim2022tubeformer">
                <a href="https://arxiv.org/abs/2404.01154">paper</a> &nbsp/&nbsp
                <a href="https://yuhuustc.github.io/UTE/">project page</a>
              </div>
            </td>
          </tr>


          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/Paper/Ming-Lite-Uni.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://arxiv.org/pdf/2505.02471">
                  <papertitle>Ming-Lite-Uni: Advancements in Unified Architecture for Natural Multimodal Interaction</papertitle>
                </a>
                <br>
                Biao Gong, 
                Cheng Zou, 
                Dandan Zheng, 
                <strong>Hu Yu</strong>,
                Jingdong Chen, 
                Jianxin Sun, 
                Junbo Zhao, 
                Jun Zhou, 
                Kaixiang Ji, 
                Lixiang Ru, 
                Libin Wang, 
                Qingpei Guo, 
                Rui Liu, 
                Weilong Chai, 
                Xinyu Xiao, 
                Ziyuan Huang
                <br>
                <em>Arxiv</em>
                <br>
              </p>
              <div class="paper" id="kim2022tubeformer">
                <a href="https://arxiv.org/pdf/2505.02471">paper</a> &nbsp/&nbsp
                <a href="https://github.com/inclusionAI/Ming/tree/Ming-Lite-Omni-Preview/Ming-unify">code</a>
              </div>
            </td>
          </tr>
          
          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/Paper/High-Quality.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://arxiv.org/abs/2308.11949">
                  <papertitle>High-quality Image Dehazing with Diffusion Model</papertitle>
                </a>
                <br>
                <strong>Hu Yu</strong>,
                Jie Huang, 
                Kaiwen Zheng, 
                Man Zhou, 
                Feng Zhao.
                <br>
                <em>Arxiv</em>
                <br>
              </p>
              <div class="paper" id="yu2021glance">
                <a href="https://arxiv.org/abs/2308.11949">paper</a> &nbsp/&nbsp
                <a href="https://github.com/yuhuUSTC/DehazeDDPM">code</a>
              </div>
            </td>
          </tr>

          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/Paper/FreePCA.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://arxiv.org/abs/2505.01172">
                  <papertitle>FreePCA: Integrating Consistency Information across Long-short Frames in Training-free Long Video Generation via Principal Component Analysis</papertitle>
                </a>
                <br>
                Jiangtong Tan, 
                <strong>Hu Yu</strong>,
                Jie Huang, 
                Jie Xiao, 
                Feng Zhao
                <br>
                <em>CVPR</em>, 2025 <strong>Spotlight</strong>
                <br>
              </p>
              <div class="paper" id="deeplab2_2021">
                <a href="https://arxiv.org/abs/2505.01172">paper</a> &nbsp/&nbsp
                <a href="https://github.com/JosephTiTan/FreePCA">code</a>
              </div>
            </td>
          </tr>
          
          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/Paper/Debias.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/08365.pdf">
                  <papertitle>Unmasking Bias in Diffusion Model Training</papertitle>
                </a>
                <br>
                Hu Yu, 
                Li Shen, 
                Jie Huang,
                Hongsheng Li, 
                Feng Zhao
                <br>
                <em>ECCV</em>, 2024
                <br>
              </p>
              <div class="paper" id="chen2021transunet">
                <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/08365.pdf">paper</a> &nbsp/&nbsp
                <a href="https://github.com/yuhuUSTC/Debias">code</a>
              </div>
            </td>
          </tr>

          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/Paper/Unleashing.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/06072.pdf">
                  <papertitle>Unleashing the Potential of the Semantic Latent Space in Diffusion Models for Image Dehazing</papertitle>
                </a>
                <br>
                Zizheng Yang,
                <strong>Hu Yu</strong>,
                Bing Li, 
                Jinghao Zhang, 
                Jie Huang,
                Feng Zhao
                <br>
                <em>ECCV</em>, 2024
                <br>
              </p>
              <div class="paper" id="yu2020mask">
                <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/06072.pdf">paper</a> &nbsp/&nbsp
              </div>
            </td>
          </tr>

          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/Paper/FreqMamba.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://arxiv.org/abs/2404.09476">
                  <papertitle>FreqMamba: Viewing Mamba from a Frequency Perspective for Image Deraining</papertitle>
                </a>
                <br>
                Zhen Zou, 
                <strong>Hu Yu</strong>,
                Zhao Feng
                <br>
                <em>ACM MM</em>, 2024
                <br>
              </p>
              <div class="paper" id="yu2020cakes">
                <a href="https://arxiv.org/abs/2404.09476">paper</a> &nbsp/&nbsp
                <a href="https://github.com/aSleepyTree/FreqMamba">code</a>
              </div>
            </td>
          </tr>

          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/Paper/FRFT.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/e66309ead63bc1410d2df261a28f602d-Paper-Conference.pdf">
                  <papertitle>Deep Fractional Fourier Transform</papertitle>
                </a>
                <br>
                <strong>Hu Yu</strong>,
                Jie Huang, 
                Lingzhi Li,
                Man Zhou, 
                Feng Zhao.
                <br>
                <em>NeurIPS</em>, 2023 <strong>Highlight</strong>
                <br>
              </p>
              <div class="paper" id="bai2020can">
                <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/e66309ead63bc1410d2df261a28f602d-Paper-Conference.pdf">paper</a>&nbsp/&nbsp
                <a href="https://github.com/yuhuUSTC/FRFT">code</a>
              </div>
            </td>
          </tr>
          
          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/Paper/VRD-IR.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Visual_Recognition-Driven_Image_Restoration_for_Multiple_Degradation_With_Intrinsic_Semantics_CVPR_2023_paper.pdf">
                  <papertitle>Visual Recognition-driven Image Restoration for Multiple Degradation with Intrinsic Semantics Recovery</papertitle>
                </a>
                <br>
                Zizheng Yang, 
                Jie Huang, 
                Jiahao Chang, 
                Man Zhou, 
                <strong>Hu Yu</strong>,
                Jinghao Zhang, 
                Feng Zhao
                <br>
                <em>CVPR</em>, 2023
                <br>
              </p>
              <div class="paper" id="xia2020detecting">
                <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Visual_Recognition-Driven_Image_Restoration_for_Multiple_Degradation_With_Intrinsic_Semantics_CVPR_2023_paper.pdf">paper</a>
              </div>
            </td>
          </tr>
          
          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
                <img src='images/Paper/IDR.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Ingredient-Oriented_Multi-Degradation_Learning_for_Image_Restoration_CVPR_2023_paper.pdf">
                  <papertitle>Ingredient-oriented Multi-degradation Learning for Image Restoration</papertitle>
                </a>
                <br>
                Jinghao Zhang, 
                Jie Huang, 
                Mingde Yao, 
                Zizheng Yang, 
                <strong>Hu Yu</strong>,
                Man Zhou, 
                Feng Zhao
                <br>
                <em>CVPR</em>, 2023
                <br>
              </p>
              <div class="paper" id="yu2019c2fnas">
                <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Ingredient-Oriented_Multi-Degradation_Learning_for_Image_Restoration_CVPR_2023_paper.pdf">paper</a> &nbsp/&nbsp
                <a href="https://github.com/JingHao99/IDR-Ingredients-oriented-Degradation-Reformulation">code</a>
              </div>
            </td>
          </tr>
          
          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
                <img src='images/Paper/Fourier_Up.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://arxiv.org/abs/2210.05171">
                  <papertitle>Deep Fourier Up-Sampling</papertitle>
                </a>
                <br>
                Man Zhou*,
                <strong>Hu Yu*</strong>,
                Jie Huang, 
                Feng Zhao, 
                Jinwei Gu, 
                Chen Change Loy, 
                Deyu Meng, 
                Chongyi Li
                <br>
                <em>NeurIPS</em>, 2022 <strong>Featured paper</strong>
                <br>
              </p>
              <div class="paper" id="li2020neural">
                <a href="https://arxiv.org/abs/2210.05171">paper</a> &nbsp/&nbsp
                <a href="https://github.com/manman1995/Deep-Fourier-Upsampling">code</a>
              </div>
            </td>
          </tr>

          
          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/Paper/SFUDA.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://arxiv.org/abs/2207.06644">
                  <papertitle>Source-Free Domain Adaptation for Real-world Image Dehazing</papertitle>
                </a>
                <br>
                <strong>Hu Yu</strong>,
                Jie Huang, 
                Yajing Liu, 
                Qi Zhu, 
                Man Zhou, 
                Feng Zhao
                <br>
                <em>ACM MM</em>, 2022
                <br>
              </p>
              <div class="paper" id="zhang2020radiology">
                <a href="https://arxiv.org/abs/2207.06644">paper</a>
              </div>
            </td>
          </tr>         
          
          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/Paper/FFMEF.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3547924">
                  <papertitle>Adaptively Learning Low-high Frequency Information Integration for Pan-sharpening</papertitle>
                </a>
                <br>
                Man Zhou, 
                Jie Huang, 
                Chongyi Li, 
                <strong>Hu Yu</strong>,
                Keyu Yan, 
                Naishan Zheng, 
                Feng Zhao
                <br>
                <em>ACM MM</em>, 2022
                <br>
              </p>
              <div class="paper" id="rstn_tmi">
                <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3547924">paper</a>
              </div>
            </td>
          </tr>           
          
          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/Paper/SFIIN.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136780268.pdf">
                  <papertitle>Spatial-Frequency Domain Information Integration for Pan-sharpening</papertitle>
                </a>
                <br>
                Man Zhou, 
                Jie Huang, 
                Keyu Yan, 
                <strong>Hu Yu</strong>,
                Xueyang Fu, 
                Aiping Liu, 
                Xian Wei, 
                Feng Zhao
                <br>
                <em>ECCV</em>, 2022
                <br>
              </p>
              <div class="paper" id="yu2019thickened">
                <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136780268.pdf">paper</a>
              </div>
            </td>
          </tr>             
          
          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/Paper/FSDGN.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136790177.pdf">
                  <papertitle>Frequency and Spatial Dual Guidance for Image Dehazing</papertitle>
                </a>
                <br>
                <strong>Hu Yu</strong>,
                Naishan Zheng, 
                Man Zhou, 
                Jie Huang, 
                Zeyu Xiao,
                Feng Zhao
                <br>
                <em>ECCV</em>, 2022
                <br>
              </p>
              <div class="paper" id="yu2018recurrent">
                <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136790177.pdf">paper</a> &nbsp/&nbsp
                <a href="https://github.com/yuhuUSTC/FSDGN">code</a>
              </div>
            </td>
          </tr>   

    
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Awards</heading>
            <ul>
              <li>National Scholarship </li>  
              <li>National Encouragement Scholarship</li> 
              <li>First-class Academic Scholarship</li> 
            </ul>
          </td>
        </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Service</heading>
            <ul>
              <li>Reviewer of NeurIPS, ICML, ICLR, CVPR, ICCV, ECCV, ACM MM, AAAI </li>  
            </ul>
          </td>
        </tr>
        </tbody></table>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;">Stolen from <a href="https://jonbarron.info/">Jon Barron</a></p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>

<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>

<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-131560165-1', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics -->

</body>

</html>
